Pensieri in codice, idee dal mondo del software a cura di Valerio Galano.
Salve a tutti e ben ritrovati per un nuovo episodio di Pensieri in codice.
Chi lavora nel campo dello sviluppo software lo avrà almeno sentito nominare,
sempre che non si sia trovato ad utilizzarlo in modo attivo.
Docker è uno strumento che negli ultimi anni ha avuto una enorme diffusione
e si è inserito in molti aspetti della produzione del software.
Nasce inizialmente come un sistema per agevolare il deployment,
cioè quella parte del ciclo di vita in cui i programmi vengono installati
sui vari ambienti di destinazione.
Nel corso degli anni però si è iniziato ad utilizzare questo strumento anche per altri scopi,
alcuni dei quali hanno notevolmente semplificato la vita a noi sviluppatori.
In questo episodio vorrei dunque dare uno sguardo d'insieme al sistema Docker
ed esaminare alcuni degli utilizzi che possono risultare interessanti per noi programmatori.
Prima di proseguire però lasciatemi dire un paio di cose.
Innanzitutto grazie ad Aldo per aver suggerito l'argomento dell'episodio di oggi nel gruppo Telegram di Pensieri in Codice.
Se anche voi volete fare lo stesso o semplicemente volete chiacchierare di argomenti legati al podcast
vi ricordo che in descrizione trovate il link per unirvi al gruppo.
Inoltre ci tengo anche a ringraziare i ragazzi della pagina Facebook Vita da Informatici la Rinascita
con i quali ho trascorso una divertentissima oretta
a registrare un episodio della serie Pezzi di Megahertz del podcast Vita da Informatici.
Abbiamo parlato di privacy, di immuni, di TikTok e tanto altro.
E abbiamo riso tantissimo.
Non perdetevi quindi l'episodio perché vi assicuro che non ve ne pentirete.
Trovate sempre il link in descrizione.
Detto questo veniamo a noi e cerchiamo un po' di capire come funziona Docker e in cosa può esserci d'aiuto.
DOCKER
Docker è quello che comunemente viene definito un sistema di virtualizzazione
anche se a breve vedremo che ha delle caratteristiche molto particolari che lo differenziano dai propri concorrenti.
Per chi non lo sapesse in parole molto semplici virtualizzare in informatica vuol dire simulare un qualcosa
a cui non si ha realmente accesso o di cui non si ha la vera disponibilità.
Si può trattare di un qualcosa di hardware, di un sistema operativo, di una piattaforma
o di qualsiasi altro componente non realmente disponibile.
Virtualizzando un qualcosa la si può utilizzare come se la si avesse a disposizione
anche se in realtà esso soffrirà di alcuni limiti
che nella maggior parte dei casi si traducono in una riduzione delle prestazioni rispetto alla propria controparte reale.
Un esempio classico di questa pratica consiste nel virtualizzare interi pc
per installarvi sistemi operativi differenti da quello ospitato sulla macchina che si sta utilizzando.
Magari vi sarà capitato di utilizzare un software come VirtualBox o VMware
per creare una di quelle che vengono comunemente chiamate macchine virtuali
e utilizzarla per installarvi un sistema operativo che volevate provare
o di cui avevate bisogno per una specifica attività.
Infatti è una pratica così comune che la stessa Microsoft ha integrato in Windows 10
uno strumento apposito chiamato WSL
proprio per semplificare la virtualizzazione di macchine con sistema Linux.
Ora, i vantaggi di avere due o più sistemi operativi che lavorano contemporaneamente sulla stessa macchina
sono innumerevoli.
Dallo sviluppare software complessi multipiattaforma
al condividere delle risorse
al mettere in piedi ambienti molto differenti da quello che è nativamente ospitato sulla macchina.
Ma di tutto questo parleremo più approfonditamente tra un po'.
Quello che è importante capire è che, come accennavo prima,
questa grande comodità ha tuttavia un risvolto piuttosto importante
e cioè il calo delle prestazioni.
Questo calo dipende da tutta una serie di implicazioni tecniche
che non sono argomento di questo podcast.
Tuttavia, quello che ci basta tenere a mente è che,
a meno che non si parli di infrastrutture appositamente progettate per la virtualizzazione
come ad esempio quelle tipicamente utilizzate per i servizi cloud,
qualsiasi macchina virtuale avrà sempre delle prestazioni notevolmente inferiori
ad una macchina reale con le stesse caratteristiche su carta.
Ed è proprio su questo aspetto che Docker, pur essendo un sistema di virtualizzazione,
fa un passo in più rispetto a quanto descritto fino ad ora.
Esso, infatti, virtualizza a livello di sistema operativo.
In gergo si dice che containerizza, cioè crea dei container virtuali.
La differenza tra una macchina virtuale ed un container virtuale
sta nel fatto che la prima simula l'hardware di un intero computer
con un certo processore, con una certa quantità di RAM, di spazio disco, eccetera.
Mentre il secondo simula solamente un'area di esecuzione
per un processo all'interno di un sistema operativo solitamente basato su Linux.
Ok, il concetto sembra complicato, ma in effetti quello che c'è da capire in parole povere è questo.
Un software o un processo che opera all'interno di un container
vede e può utilizzare un sottoinsieme delle risorse del sistema originale
e in più può anche utilizzare alcuni altri componenti virtualizzati.
Il container definisce dunque dove il software può leggere o scrivere
di quali altri software può fare uso, quali connessioni può stabilire, e così via.
In ogni controller si possono poi ovviamente installare specifici programmi
con una loro specifica versione in modo da rendere l'ambiente interno al container
adatto all'obiettivo che si intende raggiungere o al processo che si vuole farci girare.
In pratica, in un qualsiasi computer su cui è installato docker
si possono avviare una serie di container con all'interno differenti versioni di vari software,
differenti accessi al filesystem, differenti servizi attivi,
il tutto senza creare macchine virtuali ma sfruttando parte dei processi del sistema operativo di base.
Ovviamente l'assenza di macchine virtuali e di un secondo strato di sistemi operativi
rende un container molto più leggero in termini di utilizzo di risorse
e risulta anche molto più flessibile da gestire per il sistema ospitante.
In pratica ciò vuol dire che anche con delle risorse limitate
si possono avere molti container attivi contemporaneamente.
Ok dunque bellissima questa containerizzazione dei processi
ma ora immagino starete anche pensando
si ma tutto sommato a cosa serve tutto ciò?
Bene la sua idea iniziale docker è stato pensato per facilitare il deploy del software
in particolare quello che deve girare su server linux
invece di sviluppare un software da installare poi su un dato sistema
lo si sviluppa direttamente all'interno di un container
successivamente invece di installare il software di server in server
dovendo quindi soddisfare i vari requisiti configurare i sistemi eccetera
si installa direttamente il container che portando con sé la maggior parte delle caratteristiche
riduce enormemente le operazioni da compiere in ogni deploy
tralasciando però il suo obiettivo ufficiale docker può risultare di grande utilità
anche nelle fasi di sviluppo di molte tipologie di software
anche nei casi in cui questi non siano destinati a rilascio su infrastrutture basate su virtualizzazione a container
io stesso utilizzo la virtualizzazione a container per praticamente tutti i miei progetti
perché mi porta a moltissimi vantaggi anche solo nella fase di sviluppo in locale sul mio pc
il primo di questi vantaggi è che posso avere un ambiente su misura per ciascun progetto
che sia il più possibile simile a quello di produzione
per esempio se io voglio sviluppare un progetto per un pc
io lavoro infatti come consulente per lo sviluppo di software per il web
e di norma un progetto web si basa almeno su un paio di applicativi
solitamente un web server come apache o nginx e un database spesso mysql o mariadb
per non parlare poi di architetture più complesse che possono includere server cache come redis
microservizi scritti in node.js o altri componenti di ogni sorta
con docker ed in particolare con un tool che prende il nome di docker compose
risulta abbastanza semplice configurare interi ambienti totalmente indipendenti
che includono combinazioni varie dei servizi necessari a far girare qualsiasi web application
dalle più comuni basate magari su wordpress o google
nelle più complicate anche completamente custom
nel lab ufficiale di docker si trovano centinaia di container già pronti per le varie necessità
si possono trovare container ufficiali rilasciati dai produttori dei vari servizi
e container personalizzati dalla community per esigenze particolari
se ho bisogno quindi di avviare un sito in wordpress posso semplicemente configurare
un docker file così si chiama il file che contiene le istruzioni di base
con un container ufficiale wordpress scegliendo la versione del CMS che preferisco
e poi avviarlo lanciando il comando docker start
a questo punto il sistema di containerizzazione si occuperà da solo
di scaricare il container con i servizi necessari e il software di base
e di avviarlo
se invece voglio simulare in modo più accurato l'ambiente di destinazione del mio software
magari per una web application più complessa
posso configurare docker con un container per ciascuno dei server
scegliendo le stesse versioni di sistema operativo che troverò in produzione
e installando le stesse versioni dei servizi
quindi docker scaricherà dei container per ciascuno dei server
e poi sarà a noi configurarle a dovere
oppure ancora posso scegliere di simulare direttamente i servizi
come il web server e il database
e allora configurerò docker di conseguenza
e lui scaricherà dei container con questo o quell'altra versione di apache o nginx o mysql
e poi docker scaricherà le stesse versioni dei servizi
e lui scaricherà dei container con questo o quell'altra versione di apache o nginx o mysql
ovviamente tutte le operazioni aggiuntive da effettuare su uno o più container di base
possono essere facilmente automatizzate nel docker file o nel docker compose
e quindi una volta trovata la configurazione che ci soddisfa
è possibile riprodurla in modo facile e veloce
per questo stesso motivo risulta anche molto semplice spostare un ambiente da un computer ad un altro
in linea di massima se vogliamo spostare un applicativo che gira completamente su docker
ci basta installare il motore docker su un secondo sistema
trasferire i file di configurazione e il contenuto di eventuali cartelle condivise
e il gioco è fatto
le possibilità sono dunque tantissime
i container che si possono condividere sulla stessa macchina
possono essere davvero molti perché essi occupano pochissimo spazio
sia in termini di memoria fisica che memoria ram quando sono in esecuzione
la ricostruzione di un ambiente una volta che i docker file e docker compose sono scritti a dovere
è un'operazione quasi completamente automatica
e tutto questo semplifica enormemente la vita dello sviluppatore
soprattutto se questi si trova a lavorare su più progetti per volta
ora so bene che nella vita reale non sono ancora tantissime le realtà
che utilizzano docker o un altro qualsiasi sistema di containerizzazione
per i propri ambienti di produzione
il passaggio ad una simile tecnologia richiede competenze e impiego di risorse
che non tutti possono o vogliono mettere in campo
l'applicazione della strategia DevOps
che poi sarebbe quella ideale in cui utilizzare questi strumenti
è ancora lontana dall'essere diffusa nella maggior parte delle realtà
e se non sapete cos'è la DevOps
vi lascio il link in descrizione dell'episodio in cui ne abbiamo parlato
tuttavia secondo me la conoscenza di docker
non può mancare tra le competenze di un qualsiasi programmatore
primo perché come abbiamo visto i vantaggi sono notevoli anche a livello di sviluppo personale
secondo perché è una strategia in grandissima espansione
e per come la vedo io farsi trovare preparati è sempre la strategia migliore
ora se vi ho convinto a sperimentare docker e docker compose
vi lascio in descrizione i link a un paio di articoli molto interessanti
del blog di Antonio Porcelli
un altro dei ragazzi che potrete sempre trovare nel gruppo Telegram di Pensieri in Codice
in questi articoli Antonio spiega in modo semplice e con vari esempi
come installare il sistema docker e come creare il vostro primo container
sono sicuro che saranno un ottimo punto di partenza
per chi si approccia per la prima volta a questo mondo
bene con questo direi che per oggi è tutto
io vi ringrazio per aver ascoltato fin qui
vi chiedo di darmi una mano condividendo questo podcast
con chi pensate che possa essere interessato all'argomento
e vi do appuntamento al prossimo episodio
ricordandovi che un informatico risolve i problemi a volte anche usando il computer
